{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80ab2245-f5c5-4057-8543-379c6d9b6d92",
   "metadata": {},
   "source": [
    "# Why does technical computing matter?\n",
    "In this module, we set the scene for the fundamental concepts that underpin contemporary data science, machine learning, and artificial intelligence. By the end of this module, you will be able to define and demonstrate mastery of the following key concepts:\n",
    "\n",
    "* __Historical Foundations:__ Technical computing is less than 100 years old, and has been driven by the need to solve complex problems in science and engineering. We will explore the key milestones that have shaped the field, from early numerical methods to the rise of high-level programming languages.\n",
    "* __Contemporary Landscape:__ The field of technical computing is diverse, with a wide range of languages, tools, and platforms available. We will survey the current state of the field, including the rise of open-source software, cloud computing, and heterogeneous computing resources.\n",
    "* __Future Directions:__ The field of technical computing is rapidly evolving, with new technologies and paradigms emerging continually. We will speculate on the future of the field, including the potential impact of quantum computing, artificial intelligence, and other emerging technologies.\n",
    "\n",
    "Let's begin with a brief history of where we were, then examine where we are now, and then speculate (wildly) about where we might go in the future. Let's get started!\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0876a69-0c4b-4e3b-8bf0-9a7d3f781b69",
   "metadata": {},
   "source": [
    "## Historical Foundations\n",
    "__Early Numerical Methods and the First Computers:__ Long before digital computers, scientists and engineers relied on hand‐computed tables and mechanical calculators to solve differential equations for astronomy, navigation, ballistics, etc.  The urgent computational needs of World War II, i.e., breaking the Enigma code, spurred the development of the ENIAC in 1945, the first large‐scale electronic computer.  \n",
    "\n",
    "> The ENIAC and its successors, such as the UNIVAC (1951) and the IBM 701 (1953), were programmed in machine code, a tedious process that required a deep knowledge of the hardware. The sheer tedium and error-proneness of hand-coding in machine-level representations laid the groundwork for the need for higher-level abstractions in programming.\n",
    "\n",
    "**FORTRAN and the Dawn of High-Level Languages:** In 1957, IBM introduced FORTRAN, the first widely adopted high-level language explicitly designed for numerical computation.  By abstracting away machine-level details, FORTRAN enabled scientists to write array operations and loops much more succinctly than in assembly, ushering in a new era of productivity.\n",
    "\n",
    "> While almost 70 years old, FORTRAN remains in use today, especially in legacy scientific applications and high-performance computing (HPC) environments. Thus, it is a testament to the enduring value of high-level abstractions in technical computing.\n",
    "\n",
    "**The Rise of C, C++, and Systems-Level Control:** During the 1970s and 1980s, C emerged as a portable systems programming language, offering both low-level memory manipulation and higher-order abstractions.  Its successor, C++, added object-oriented features that allowed engineers to build large, modular numerical libraries. The C/C++ ecosystem has become the backbone of scientific computing, enabling efficient implementations of numerical algorithms while maintaining a degree of portability across various platforms.\n",
    "\n",
    "> Today, performance-critical libraries in linear algebra (e.g., BLAS, LAPACK) and machine learning frameworks (e.g., TensorFlow, PyTorch backends) are often implemented in C or C++ to strike a balance between speed and maintainability.\n",
    "\n",
    "**MATLAB, Python, Julia, and the Rise of Fast Development:** MATLAB’s debut in 1984 brought an interactive environment where students and researchers could combine matrix algebra, visualization, and simple scripting in one tool. It is often one of the first languages taught in engineering and science courses due to its ease of use and powerful built-in functions. \n",
    "\n",
    "> In the 2000s, Python, with libraries such as NumPy, SciPy, and Matplotlib, provided a free, open-source alternative that integrated seamlessly with C/C++ backends. More recently, since 2012, Julia has gained traction by delivering Python-style dynamism with C-level performance, further lowering the barrier to entry for complex modeling and data analysis.\n",
    "\n",
    "\n",
    "Finally, the development of technical computing has been greatly influenced by the increasing availability of powerful and specialized hardware, e.g., GPUs, TPUs, multicore systems, etc., the rise of the internet, and the growing importance of data-driven decision-making across all fields of science and engineering.\n",
    "\n",
    "That's where we were, now let's look at where we are now.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0e86b6",
   "metadata": {},
   "source": [
    "## Contemporary Landscape\n",
    "Today, technical computing encompasses a wide range of tools and languages, each with its strengths and weaknesses, as well as a diverse set of problem areas. The landscape is characterized by:\n",
    "\n",
    "- **Diversity of Languages:** From low-level languages like C and C++ to high-level languages like Python and Julia, each language serves different needs. For example, C/C++ is often used for performance-critical applications, while Python is favored for its ease of use and extensive libraries. The Julia language, which we will focus on in this course, aims to combine the best of both worlds by providing high performance with a user-friendly syntax.\n",
    "\n",
    "* **Cloud and Heterogeneous Computing Resources** The advent of cloud services and specialized hardware (GPUs, TPUs, FPGAs) has enabled mainstream access to petaflops of computing power.  Researchers can now rent GPU or TPU instances by the hour, scaling their workflows elastically without maintaining their own data centers. They can mix and match CPUs, GPUs, and other accelerators to optimize cost and performance.\n",
    "\n",
    "* **Open-Source Ecosystems and Reproducibility** Open-source software like NumPy, SciPy, and TensorFlow has enabled researchers and developers to build complex applications without costly software. Platforms like GitHub host many scientific libraries, promoting sharing and collaboration. Container tools (e.g., Docker) and notebooks (e.g., Jupyter) ensure reproducibility, transparency, and faster innovation.\n",
    "\n",
    "### Significant Achievements\n",
    "The (re)rise of machine learning and artificial intelligence has impacted technical computing in significant ways, but it has also introduced new challenges. Are we headed for a golden age, or another AI winter? Let's take a look at some of the significant achievements and challenges in this area:\n",
    "\n",
    "* __Autonomous Systems__: As autonomous systems like self-driving cars and robots become more common, the importance of robust, reliable, and interpretable algorithms increases. This necessity involves advances in both algorithm development and the hardware and software infrastructure needed for real-time decision-making. It's not only about building machines capable of learning but also ensuring they operate safely and effectively in complex, ever-changing environments that go beyond their initial training data.\n",
    "\n",
    "* __Impact on Scientific Research__: Advancements like AlphaFold have revolutionized fields such as protein folding, enabling researchers to predict protein structures with unmatched accuracy. This influences drug discovery and our understanding of biological processes. Additionally, the ability to analyze large datasets and build predictive models has transformed areas like genomics, climate science, and materials science. However, it also raises concerns about reproducibility, transparency, and ethical data use. For example, applying machine learning in healthcare requires careful attention to patient privacy and data security.\n",
    "\n",
    "* __Ethical Considerations__: It is undeniable that the rise of machine learning and AI, including Large Language Models (LLMs), has transformed our world. However, these technologies have raised important ethical questions. Issues like bias in algorithms, data privacy, and the risk of AI misuse need careful thought and regulation. As technical computing keeps evolving, it is essential to address these challenges to ensure we gain the benefits of these technologies while minimizing potential harms.\n",
    "\n",
    "* __Societal Impact__: The influence of technical computing on society is significant. From improving healthcare outcomes through predictive analytics to optimizing transportation systems with real-time traffic management, the range of applications is extensive. However, the fast pace of technological progress also raises concerns about job loss, economic disparity, and the need for workforce reskilling. Additionally, the environmental effects of large-scale computing, including energy use and electronic waste, are vital issues that must be addressed as we advance.\n",
    "\n",
    "The applications of technical computing are vast, spanning scientific research and engineering, as well as finance, healthcare, and other fields. It's an exciting time in the field, but where are we headed?\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a91e23",
   "metadata": {},
   "source": [
    "## The Future\n",
    "\n",
    "Who knows what the future holds? A golden age of society or Skynet and killer robots? While we can't predict the future with certainty, let's examine some key trends and challenges that are likely to shape the field in the years to come.\n",
    "\n",
    "* **Exascale Performance and Energy Efficiency**\n",
    "  As the community moves toward exascale ($10^{18}$ FLOPS) systems, writing algorithms that effectively exploit millions of cores while minimizing energy consumption is paramount. Researchers must develop new parallelization strategies, reduce data movement, and embrace low-precision arithmetic where tolerable to stay within power and cooling budgets.\n",
    "\n",
    "* **Quantum Computing and Hybrid Architectures**\n",
    "  Quantum computers promise to solve certain classes of problems, e.g., prime factorization, or combinatorial optimization, exponentially faster than classical machines. Over the coming decade, integrating noisy intermediate-scale quantum (NISQ) devices with classical HPC will require new hybrid algorithms, error-mitigation techniques, and software frameworks that orchestrate classical and quantum workloads seamlessly.\n",
    "\n",
    "* **Algorithmic Robustness, Uncertainty, and Trust**\n",
    "  Complex simulations and AI models must quantify their uncertainty, whether arising from input data, model approximations, or numerical instability, to be reliable in critical applications such as medicine, autonomous systems, or finance. Explainable AI techniques and rigorous verification of scientific codes will be essential to earn stakeholders’ trust.\n",
    "\n",
    "* **Sustainable Software and Data Management**\n",
    "  Long-term scientific progress depends on maintaining and curating software and datasets across decades. Establishing community standards for metadata, version control, and archiveable containers will ensure that future researchers can build on—and not have to rewrite—today’s computational work.\n",
    "\n",
    "* **Bridging Scales and Integrating Disciplines**\n",
    "  Many grand challenges require coupling models at vastly different scales (from quantum mechanics to continuum mechanics) and integrating expertise from physics, chemistry, biology, engineering, and data science. Designing frameworks that enable the seamless exchange of data and solvers across these domains will be crucial for tackling problems such as materials design, personalized medicine, and sustainable energy.\n",
    "\n",
    "However, before we can tackle these challenges, we must first understand the fundamental concepts that underpin technical computing. \n",
    "\n",
    "In this module, we will begin at the beginning, exploring the basic building blocks of technical computing, i.e., data types and type systems, and introduce the Julia programming language, which is designed for high-performance numerical and scientific computing.\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
